import streamlit as st
import re
import json
import pandas as pd
import chromadb
from chromadb.utils import embedding_functions
from typing import List, Dict, Any, Tuple
from dataclasses import dataclass
import hashlib
import requests


# é¡µé¢é…ç½®
st.set_page_config(
    page_title="è®ºè¯­æ™ºèƒ½é—®ç­”ç³»ç»Ÿ",
    page_icon="ğŸ“š",
    layout="wide",
    initial_sidebar_state="expanded"
)

@dataclass
class LunyuSegment:
    """è®ºè¯­ç‰‡æ®µæ•°æ®ç»“æ„"""
    chapter: str
    speaker: str
    content: str
    topic: str
    segment_id: str

class LunyuRAG:
    """è®ºè¯­RAGç³»ç»Ÿ"""
    
    def __init__(self):
        self.client = chromadb.Client()
        self.collection_name = "lunyu_collection"
        self.segments: List[LunyuSegment] = []
        
        # åˆå§‹åŒ–å‘é‡æ•°æ®åº“
        try:
            self.collection = self.client.get_collection(self.collection_name)
        except:
            self.collection = self.client.create_collection(
                name=self.collection_name,
                metadata={"description": "è®ºè¯­å‘é‡æ•°æ®åº“"}
            )
    
    def preprocess_lunyu_data(self, raw_text: str) -> List[LunyuSegment]:
        """é¢„å¤„ç†è®ºè¯­æ•°æ®"""
        segments = []
        segment_counter = 0  # æ·»åŠ è®¡æ•°å™¨ç¡®ä¿å”¯ä¸€æ€§
        
        # æ¸…ç†æ–‡æœ¬
        text = raw_text.strip()
        
        # æŒ‰ç¯‡ç« åˆ†å‰²
        chapters = []
        current_chapter = ""
        current_content = []
        
        lines = text.split('\n')
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # æ£€æµ‹ç¯‡ç« æ ‡é¢˜ï¼ˆå¦‚"å­¦è€Œç¬¬ä¸€"ï¼‰
            if re.match(r'[^ç¬¬]*ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+', line):
                if current_chapter and current_content:
                    chapters.append((current_chapter, '\n'.join(current_content)))
                current_chapter = line
                current_content = []
            else:
                current_content.append(line)
        
        # æ·»åŠ æœ€åä¸€ç« 
        if current_chapter and current_content:
            chapters.append((current_chapter, '\n'.join(current_content)))
        
        for chapter_name, chapter_content in chapters:
            sentences = self.split_sentences(chapter_content)
            
            for sentence in sentences:
                sentence = sentence.strip()
                if len(sentence) < 10:
                    continue
                
                speaker = self.identify_speaker(sentence)
                topic = self.classify_topic(sentence)
                
                # ä¿®æ”¹è¿™é‡Œï¼šä½¿ç”¨è®¡æ•°å™¨ç”Ÿæˆå”¯ä¸€ID
                segment_id = f"{segment_counter:04d}"  # 0001, 0002, 0003...
                segment_counter += 1
                
                segment = LunyuSegment(
                    chapter=chapter_name,
                    speaker=speaker,
                    content=sentence,
                    topic=topic,
                    segment_id=segment_id
                )
                segments.append(segment)
        
        return segments
    
    def split_sentences(self, text: str) -> List[str]:
        """åˆ†å‰²å¥å­"""
        # æŒ‰ç…§æ˜æ˜¾çš„åˆ†å¥æ ‡è®°åˆ†å‰²
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ]', text)
        
        # è¿›ä¸€æ­¥å¤„ç†å¤æ‚å¯¹è¯
        result = []
        for sentence in sentences:
            sentence = sentence.strip()
            if not sentence:
                continue
                
            # å¦‚æœå¥å­å¾ˆé•¿ï¼Œå°è¯•æŒ‰å¯¹è¯åˆ†å‰²
            if len(sentence) > 100 and 'æ›°' in sentence:
                parts = re.split(r'([^æ›°]{1,20}æ›°)', sentence)
                temp_sentence = ""
                for part in parts:
                    temp_sentence += part
                    if 'æ›°' in part and temp_sentence.strip():
                        result.append(temp_sentence.strip())
                        temp_sentence = ""
                if temp_sentence.strip():
                    result.append(temp_sentence.strip())
            else:
                result.append(sentence)
        
        return result
    
    def identify_speaker(self, text: str) -> str:
        """è¯†åˆ«è¯´è¯äºº"""
        speakers = {
            'å­æ›°': 'å­”å­',
            'æœ‰å­æ›°': 'æœ‰å­',
            'æ›¾å­æ›°': 'æ›¾å­',
            'å­å¤æ›°': 'å­å¤',
            'å­æ¸¸æ›°': 'å­æ¸¸',
            'å­è´¡æ›°': 'å­è´¡',
            'å­è´¡é—®': 'å­è´¡',
            'å­è·¯æ›°': 'å­è·¯',
            'å­è·¯é—®': 'å­è·¯',
            'é¢œæ¸Šæ›°': 'é¢œæ¸Š',
            'é¢œæ¸Šé—®': 'é¢œæ¸Š',
            'å­å¼ æ›°': 'å­å¼ ',
            'å­å¼ é—®': 'å­å¼ ',
            'æ¨Šè¿Ÿé—®': 'æ¨Šè¿Ÿ',
            'å­£åº·å­é—®': 'å­£åº·å­',
            'å“€å…¬é—®': 'å“€å…¬',
            'å®šå…¬é—®': 'å®šå…¬'
        }
        
        for pattern, speaker in speakers.items():
            if text.startswith(pattern):
                return speaker
        
        # æ£€æŸ¥å…¶ä»–å¯¹è¯æ¨¡å¼
        if 'é—®æ›°' in text or 'é—®äº' in text:
            match = re.search(r'([^é—®]+)é—®', text)
            if match:
                return match.group(1)
        
        return 'å­”å­'  # é»˜è®¤
    
    def classify_topic(self, text: str) -> str:
        """åˆ†ç±»è¯é¢˜"""
        topics = {
            'å­¦ä¹ æ•™è‚²': ['å­¦', 'ä¹ ', 'æ•™', 'è¯²', 'çŸ¥', 'é—®', 'æ€'],
            'å“å¾·ä¿®å…»': ['ä»', 'ä¹‰', 'ç¤¼', 'æ™º', 'ä¿¡', 'å¾·', 'å–„', 'ä¿®'],
            'æ”¿æ²»æ²»ç†': ['æ”¿', 'å›', 'è‡£', 'æ°‘', 'å›½', 'æ²»', 'é‚¦'],
            'äººé™…å…³ç³»': ['å‹', 'æœ‹', 'äº¤', 'äºº', 'äº²', 'ç¾¤'],
            'äººç”Ÿå“²å­¦': ['é“', 'å¤©', 'å‘½', 'ç”Ÿ', 'æ­»', 'ä¹', 'å¿§'],
            'ç¤¾ä¼šç¤¼ä»ª': ['ç¤¼', 'ä¹', 'ç¥­', 'ä¸§', 'å©š', 'å† ']
        }
        
        for topic, keywords in topics.items():
            if any(keyword in text for keyword in keywords):
                return topic
        
        return 'å…¶ä»–'
    
    def load_data(self, text_data: str):
        """åŠ è½½æ•°æ®åˆ°å‘é‡æ•°æ®åº“"""
        with st.spinner("æ­£åœ¨å¤„ç†è®ºè¯­æ•°æ®..."):
            # é¢„å¤„ç†æ•°æ®
            self.segments = self.preprocess_lunyu_data(text_data)
            
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ•°æ®
            if self.collection.count() > 0:
                # æ¸…ç©ºæ—§æ•°æ®
                self.collection.delete(where={})
            
            # æ‰¹é‡å­˜å‚¨
            documents = []
            metadatas = []
            ids = []
            
            for segment in self.segments:
                documents.append(segment.content)
                metadatas.append({
                    'chapter': segment.chapter,
                    'speaker': segment.speaker,
                    'topic': segment.topic
                })
                ids.append(segment.segment_id)
            
            # åˆ†æ‰¹æ·»åŠ åˆ°å‘é‡æ•°æ®åº“
            batch_size = 50
            for i in range(0, len(documents), batch_size):
                batch_docs = documents[i:i+batch_size]
                batch_metas = metadatas[i:i+batch_size]
                batch_ids = ids[i:i+batch_size]
                
                self.collection.add(
                    documents=batch_docs,
                    metadatas=batch_metas,
                    ids=batch_ids
                )
        
        return len(self.segments)
    
    def search(self, query: str, top_k: int = 5) -> List[Dict[str, Any]]:
        """æœç´¢ç›¸å…³å†…å®¹"""
        try:
            results = self.collection.query(
                query_texts=[query],
                n_results=top_k
            )
            
            search_results = []
            if results['documents'] and results['documents'][0]:
                for i, doc in enumerate(results['documents'][0]):
                    result = {
                        'content': doc,
                        'metadata': results['metadatas'][0][i],
                        'score': 1 - results['distances'][0][i] if results['distances'] else 1.0
                    }
                    search_results.append(result)
            
            return search_results
        except Exception as e:
            st.error(f"æœç´¢å‡ºé”™: {e}")
            return []
    
    def call_deepseek_api(self, prompt: str, api_key: str) -> str:
        """è°ƒç”¨DeepSeek API"""
        try:
            headers = {
                'Content-Type': 'application/json',
                'Authorization': f'Bearer {api_key}'
            }
            
            data = {
                'model': 'deepseek-chat',
                'messages': [
                    {'role': 'system', 'content': 'ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å¤å…¸æ–‡å­¦å­¦è€…ï¼Œç²¾é€šè®ºè¯­ç­‰å¤ä»£å…¸ç±ã€‚'},
                    {'role': 'user', 'content': prompt}
                ],
                'stream': False,
                'max_tokens': 1000,
                'temperature': 0.7
            }
            
            response = requests.post(
                'https://api.deepseek.com/chat/completions',
                headers=headers,
                json=data,
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                return result['choices'][0]['message']['content']
            else:
                return f"APIè°ƒç”¨å¤±è´¥: {response.status_code} - {response.text}"
                
        except Exception as e:
            return f"APIè°ƒç”¨å‡ºé”™: {str(e)}"
    
    def generate_answer(self, query: str, context: List[Dict[str, Any]], api_key: str = None) -> str:
        """ç”Ÿæˆç­”æ¡ˆ"""
        if not context:
            return "æŠ±æ­‰ï¼Œæ²¡æœ‰æ‰¾åˆ°ç›¸å…³çš„è®ºè¯­å†…å®¹ã€‚"
        
        # æ„å»ºä¸Šä¸‹æ–‡
        context_text = ""
        for item in context[:3]:  # ä½¿ç”¨å‰3ä¸ªæœ€ç›¸å…³çš„ç»“æœ
            meta = item['metadata']
            context_text += f"ã€{meta['chapter']}ã€‘{meta['speaker']}: {item['content']}\n\n"
        
        # æ„å»ºæç¤ºè¯
        prompt = f"""ä½ æ˜¯ä¸€ä½ç²¾é€šä¸­å›½å¤å…¸æ–‡å­¦çš„å­¦è€…ï¼Œè¯·åŸºäºä»¥ä¸‹è®ºè¯­åŸæ–‡å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

ç›¸å…³è®ºè¯­åŸæ–‡ï¼š
{context_text.strip()}

ç”¨æˆ·é—®é¢˜ï¼š{query}

è¯·æŒ‰ä»¥ä¸‹è¦æ±‚å›ç­”ï¼š
1. é¦–å…ˆå¼•ç”¨ç›¸å…³çš„åŸæ–‡
2. è§£é‡Šå¤æ–‡çš„å«ä¹‰
3. ç»“åˆç°ä»£è§‚ç‚¹è¿›è¡Œé˜è¿°
4. å›ç­”è¦ç®€æ´æ˜äº†ï¼Œé‡ç‚¹çªå‡º

å›ç­”ï¼š"""

        # å¦‚æœæœ‰APIå¯†é’¥ï¼Œä½¿ç”¨DeepSeek API
        if api_key and api_key.strip():
            try:
                answer = self.call_deepseek_api(prompt, api_key.strip())
                return answer
            except Exception as e:
                return f"AIç”Ÿæˆå›ç­”æ—¶å‡ºé”™: {e}\n\nåŸºäºæœç´¢ç»“æœï¼š\n{context_text}"
        else:
            # ç”Ÿæˆç®€å•çš„åŸºäºè§„åˆ™çš„å›ç­”
            answer = f"å…³äºã€Œ{query}ã€ï¼Œæ ¹æ®è®ºè¯­ç›¸å…³å†…å®¹ï¼š\n\n"
            
            for i, item in enumerate(context[:3], 1):
                meta = item['metadata']
                answer += f"**{i}. {meta['chapter']} - {meta['speaker']}**\n"
                answer += f"åŸæ–‡ï¼šã€Œ{item['content']}ã€\n"
                answer += f"è¯é¢˜ï¼š{meta['topic']} | ç›¸å…³åº¦ï¼š{item['score']:.2f}\n\n"
            
            # æ·»åŠ ç®€å•æ€»ç»“
            main_topics = list(set([item['metadata']['topic'] for item in context[:3]]))
            if main_topics:
                answer += f"ğŸ’¡ **æ€»ç»“**ï¼šä»¥ä¸Šå†…å®¹ä¸»è¦æ¶‰åŠ{' '.join(main_topics)}ç­‰æ–¹é¢çš„æ€æƒ³ã€‚"
            
            return answer

def load_lunyu_from_file():
    """ä»è®ºè¯­.txtæ–‡ä»¶ä¸­åŠ è½½æ•°æ®"""
    try:
        with open('è®ºè¯­.txt', 'r', encoding='utf-8') as file:
            content = file.read()
        
        # æå–<content></content>æ ‡ç­¾ä¸­çš„å†…å®¹
        match = re.search(r'<content>(.*?)</content>', content, re.DOTALL)
        if match:
            return match.group(1).strip()
        else:
            st.error("æœªæ‰¾åˆ°<content>æ ‡ç­¾")
            return ""
    except FileNotFoundError:
        st.error("æœªæ‰¾åˆ°è®ºè¯­.txtæ–‡ä»¶")
        return ""
    except Exception as e:
        st.error(f"è¯»å–æ–‡ä»¶å‡ºé”™: {e}")
        return ""


def main():
    """ä¸»åº”ç”¨"""
    st.title("ğŸ“š è®ºè¯­æ™ºèƒ½é—®ç­”ç³»ç»Ÿ")
    st.markdown("*åŸºäºRAGæŠ€æœ¯çš„å¤å…¸æ–‡çŒ®é—®ç­”ç³»ç»Ÿ*")
    st.markdown("---")
    
    # åˆå§‹åŒ–ç³»ç»Ÿ
    if 'rag_system' not in st.session_state:
        try:
            st.session_state.rag_system = LunyuRAG()
        except Exception as e:
            st.error(f"ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
            st.info("å»ºè®®ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬ï¼Œæˆ–æ£€æŸ¥ChromaDBå®‰è£…ã€‚")
            return
    
    # ä¾§è¾¹æ é…ç½®
    with st.sidebar:
        st.header("âš™ï¸ ç³»ç»Ÿé…ç½®")
        
        # APIé…ç½®
        st.subheader("AIé…ç½®")
        api_key = st.text_input(
            "DeepSeek API Key",
            type="password",
            help="è¾“å…¥ä½ çš„DeepSeek APIå¯†é’¥ä»¥è·å¾—AIå›ç­”ï¼Œç•™ç©ºåˆ™ä½¿ç”¨åŸºç¡€å›ç­”"
        )
        
        if not api_key:
            st.info("ğŸ’¡ æ²¡æœ‰APIå¯†é’¥ï¼Ÿç³»ç»Ÿä»å¯æœç´¢å’Œæ˜¾ç¤ºç›¸å…³åŸæ–‡ï¼Œåªæ˜¯ä¸ä¼šæœ‰AIç”Ÿæˆçš„å›ç­”ã€‚")
        
        # æœç´¢é…ç½®
        st.subheader("æœç´¢è®¾ç½®")
        top_k = st.slider("è¿”å›ç»“æœæ•°é‡", 1, 10, 5)
        
        # æ•°æ®ç®¡ç†
        st.subheader("æ•°æ®ç®¡ç†")

        
        if st.button("ğŸ”„ åŠ è½½è®ºè¯­æ•°æ®", type="primary"):
            try:
                with st.spinner("æ­£åœ¨åŠ è½½æ•°æ®..."):
                    lunyu_data = load_lunyu_from_file()  # ä»æ–‡ä»¶åŠ è½½
                    if lunyu_data:
                        count = st.session_state.rag_system.load_data(lunyu_data)
                        st.success(f"âœ… æˆåŠŸåŠ è½½ {count} æ¡æ•°æ®ï¼")
            except Exception as e:
                st.error(f"æ•°æ®åŠ è½½å¤±è´¥: {e}")
        
        # æ˜¾ç¤ºæ•°æ®çŠ¶æ€
        try:
            data_count = st.session_state.rag_system.collection.count()
            st.metric("å·²åŠ è½½æ•°æ®", f"{data_count} æ¡")
        except:
            st.metric("å·²åŠ è½½æ•°æ®", "0 æ¡")
    
    # ä¸»ç•Œé¢
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.header("ğŸ’¬ æ™ºèƒ½é—®ç­”")
        
        # é¢„è®¾é—®é¢˜
        st.subheader("ğŸ“‹ å¸¸è§é—®é¢˜")
        example_questions = [
            "å­”å­å¯¹å­¦ä¹ çš„çœ‹æ³•æ˜¯ä»€ä¹ˆï¼Ÿ",
            "ä»€ä¹ˆæ˜¯ä»ï¼Ÿ",
            "å›å­å’Œå°äººçš„åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿ",
            "å­”å­çš„æ•™è‚²æ€æƒ³æœ‰å“ªäº›ï¼Ÿ",
            "è®ºè¯­ä¸­å…³äºæ”¿æ²»çš„è§‚ç‚¹",
            "å¦‚ä½•ä¿®èº«å…»æ€§ï¼Ÿ"
        ]
        
        selected_question = st.selectbox(
            "é€‰æ‹©ä¸€ä¸ªé—®é¢˜ï¼Œæˆ–åœ¨ä¸‹æ–¹è¾“å…¥è‡ªå®šä¹‰é—®é¢˜ï¼š",
            [""] + example_questions
        )
        
        # é—®é¢˜è¾“å…¥
        if selected_question:
            query = st.text_input("æ‚¨çš„é—®é¢˜", value=selected_question)
        else:
            query = st.text_input("æ‚¨çš„é—®é¢˜", placeholder="è¯·è¾“å…¥æ‚¨æƒ³äº†è§£çš„å†…å®¹...")
        
        # æœç´¢å’Œé—®ç­”
        if st.button("ğŸ” æé—®", type="primary") and query:
            with st.spinner("æ­£åœ¨æœç´¢ç›¸å…³å†…å®¹..."):
                # æœç´¢
                search_results = st.session_state.rag_system.search(query, top_k)
                
                if search_results:
                    # æ˜¾ç¤ºæœç´¢ç»“æœ
                    st.subheader("ğŸ“– ç›¸å…³åŸæ–‡")
                    for i, result in enumerate(search_results):
                        meta = result['metadata']
                        with st.expander(f"ğŸ“œ {meta['chapter']} - {meta['speaker']} (ç›¸å…³åº¦: {result['score']:.2f})"):
                            st.write(f"**è¯é¢˜**: {meta['topic']}")
                            st.write(f"**åŸæ–‡**: {result['content']}")
                    
                    # ç”Ÿæˆç­”æ¡ˆ
                    st.subheader("ğŸ¤– æ™ºèƒ½è§£ç­”")
                    with st.spinner("æ­£åœ¨ç”Ÿæˆå›ç­”..."):
                        answer = st.session_state.rag_system.generate_answer(
                            query, search_results, api_key
                        )
                        st.markdown(answer)
                else:
                    st.warning("ğŸ˜” æ²¡æœ‰æ‰¾åˆ°ç›¸å…³å†…å®¹ï¼Œè¯·å°è¯•å…¶ä»–é—®é¢˜ã€‚")
    
    with col2:
        st.header("ğŸ“Š ç³»ç»Ÿä¿¡æ¯")
        
        # ç³»ç»ŸçŠ¶æ€
        st.info("""
        **ğŸ”§ ç³»ç»ŸçŠ¶æ€**
        - âœ… ChromaDBå‘é‡æœç´¢
        - âœ… å¤æ–‡æ™ºèƒ½åˆ†æ
        - ğŸ”‘ DeepSeek AIå›ç­” (éœ€APIå¯†é’¥)
        - ğŸ“Š æ•°æ®ç»Ÿè®¡åˆ†æ
        """)
        
        # æ•°æ®ç»Ÿè®¡
        if hasattr(st.session_state.rag_system, 'segments') and st.session_state.rag_system.segments:
            segments = st.session_state.rag_system.segments
            
            st.metric("æ–‡æœ¬ç‰‡æ®µ", len(segments))
            
            # è¯´è¯äººç»Ÿè®¡
            speakers = {}
            topics = {}
            chapters = {}
            
            for seg in segments:
                speakers[seg.speaker] = speakers.get(seg.speaker, 0) + 1
                topics[seg.topic] = topics.get(seg.topic, 0) + 1
                chapters[seg.chapter] = chapters.get(seg.chapter, 0) + 1
            
            st.subheader("ğŸ—£ï¸ è¯´è¯äººåˆ†å¸ƒ")
            for speaker, count in sorted(speakers.items(), key=lambda x: x[1], reverse=True)[:5]:
                st.write(f"**{speaker}**: {count} æ¡")
            
            st.subheader("ğŸ·ï¸ è¯é¢˜åˆ†å¸ƒ")
            for topic, count in sorted(topics.items(), key=lambda x: x[1], reverse=True)[:5]:
                st.write(f"**{topic}**: {count} æ¡")
        
        # ä½¿ç”¨è¯´æ˜
        st.subheader("ğŸ’¡ ä½¿ç”¨æç¤º")
        st.markdown("""
        **åŸºç¡€åŠŸèƒ½**ï¼ˆæ— éœ€APIï¼‰:
        - ğŸ” æœç´¢è®ºè¯­ç›¸å…³å†…å®¹
        - ğŸ“– æ˜¾ç¤ºåŸæ–‡å’Œå‡ºå¤„
        - ğŸ“Š æŸ¥çœ‹æ•°æ®ç»Ÿè®¡
        
        **é«˜çº§åŠŸèƒ½**ï¼ˆéœ€APIå¯†é’¥ï¼‰:
        - ğŸ¤– AIæ™ºèƒ½å›ç­”
        - ğŸ’¬ å¤æ–‡ç°ä»£è§£é‡Š
        - ğŸ¯ ä¸ªæ€§åŒ–é—®ç­”
        """)

if __name__ == "__main__":
    # æ ·å¼ä¼˜åŒ–
    st.markdown("""
    <style>
    .stApp {
        background-color: #f8f9fa;
    }
    .stButton>button {
        border-radius: 20px;
    }
    .stSelectbox>div>div>div {
        border-radius: 10px;
    }
    .stExpander {
        border-radius: 10px;
    }
    </style>
    """, unsafe_allow_html=True)
    
    main()