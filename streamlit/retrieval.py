import streamlit as st
import numpy as np
import jieba
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import asdict
from config import HAS_BM25, HAS_RERANKER
from models import AncientTextSegment

if HAS_BM25:
    from rank_bm25 import BM25Okapi

if HAS_RERANKER:
    from sentence_transformers import CrossEncoder

        
class BGEReranker:
    """BGEé‡æ’åºå™¨ - ä¿®å¤ç‰ˆ"""
    
    # ç±»çº§åˆ«çš„æ¨¡å‹ç¼“å­˜ï¼Œé¿å…é‡å¤åŠ è½½
    _model_cache = {}
    _loading_status = {}
    
    def __init__(self, model_name: str = "BAAI/bge-reranker-large"):
        self.model_name = model_name
        self.model = None
        self.is_loaded = False
        
        # æ£€æŸ¥æ˜¯å¦å·²ç»åŠ è½½è¿‡è¯¥æ¨¡å‹
        if model_name in self._model_cache:
            self.model = self._model_cache[model_name]
            self.is_loaded = self._loading_status[model_name]
            if self.is_loaded:
                st.info(f"âœ… ä½¿ç”¨å·²ç¼“å­˜çš„é‡æ’åºæ¨¡å‹: {model_name}")
    
    def _load_model(self):
        """å»¶è¿ŸåŠ è½½æ¨¡å‹ - æ”¹è¿›ç‰ˆ"""
        if not HAS_RERANKER:
            st.warning("âš ï¸ é‡æ’åºåŠŸèƒ½éœ€è¦å®‰è£… sentence-transformers")
            st.code("pip install sentence-transformers torch")
            return False
        
        # å¦‚æœå·²ç»åœ¨åŠ è½½ä¸­ï¼Œç›´æ¥è¿”å›
        if self.model_name in self._loading_status and self._loading_status[self.model_name]:
            return True
        
        # å¦‚æœå·²ç»åŠ è½½è¿‡ä¸”å¤±è´¥äº†ï¼Œä¸å†é‡è¯•
        if self.model_name in self._model_cache and not self._loading_status[self.model_name]:
            st.warning(f"é‡æ’åºæ¨¡å‹ {self.model_name} ä¹‹å‰åŠ è½½å¤±è´¥ï¼Œè·³è¿‡é‡æ’åº")
            return False
        
        try:
            with st.spinner(f"é¦–æ¬¡åŠ è½½é‡æ’åºæ¨¡å‹ {self.model_name}ï¼Œè¯·ç¨å€™..."):
                self.model = CrossEncoder(self.model_name)
                
                # ç¼“å­˜æ¨¡å‹å’ŒçŠ¶æ€
                self._model_cache[self.model_name] = self.model
                self._loading_status[self.model_name] = True
                self.is_loaded = True
                
                st.success(f"âœ… é‡æ’åºæ¨¡å‹åŠ è½½æˆåŠŸ: {self.model_name}")
                return True
                
        except Exception as e:
            error_msg = f"é‡æ’åºæ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}"
            st.error(f"âŒ {error_msg}")
            
            # ç¼“å­˜å¤±è´¥çŠ¶æ€ï¼Œé¿å…é‡å¤å°è¯•
            self._model_cache[self.model_name] = None
            self._loading_status[self.model_name] = False
            self.is_loaded = False
            
            # æä¾›è§£å†³å»ºè®®
            if "No module named" in str(e):
                st.info("ğŸ’¡ è¯·å®‰è£…ä¾èµ–: pip install sentence-transformers torch")
            elif "CUDA" in str(e) or "GPU" in str(e):
                st.info("ğŸ’¡ GPUç›¸å…³é”™è¯¯ï¼Œè¯·æ£€æŸ¥CUDAç¯å¢ƒæˆ–åˆ‡æ¢åˆ°CPUæ¨¡å¼")
            elif "timeout" in str(e).lower():
                st.info("ğŸ’¡ ç½‘ç»œè¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ä½¿ç”¨æœ¬åœ°æ¨¡å‹")
            
            return False
    
    def ensure_loaded(self) -> bool:
        """ç¡®ä¿æ¨¡å‹å·²åŠ è½½"""
        if self.is_loaded and self.model is not None:
            return True
        return self._load_model()
    
    def rerank(self, query: str, candidates: List[Dict], top_k: int = 5) -> List[Dict]:
        """é‡æ’åºå€™é€‰ç»“æœ - æ”¹è¿›ç‰ˆ"""
        # æ£€æŸ¥å€™é€‰ç»“æœ
        if not candidates:
            return []
        
        # ç¡®ä¿æ¨¡å‹å·²åŠ è½½
        if not self.ensure_loaded():
            st.warning("é‡æ’åºæ¨¡å‹ä¸å¯ç”¨ï¼Œè¿”å›åŸå§‹æ’åºç»“æœ")
            return candidates[:top_k]
        
        try:
            # é™åˆ¶å€™é€‰æ•°é‡ï¼Œé¿å…å¤„ç†è¿‡å¤šç»“æœ
            max_candidates = min(len(candidates), 100)  # æœ€å¤šå¤„ç†100ä¸ªå€™é€‰
            limited_candidates = candidates[:max_candidates]
            
            # å‡†å¤‡æŸ¥è¯¢-æ–‡æ¡£å¯¹
            pairs = [(query, candidate['content']) for candidate in limited_candidates]
            
            # è·å–é‡æ’åºåˆ†æ•°
            with st.spinner("æ­£åœ¨æ‰§è¡Œæ·±åº¦é‡æ’åº..."):
                scores = self.model.predict(pairs)
            
            # æ›´æ–°å€™é€‰ç»“æœçš„åˆ†æ•°
            for i, candidate in enumerate(limited_candidates):
                candidate['rerank_score'] = float(scores[i])
                # ä¿ç•™åŸå§‹åˆ†æ•°ç”¨äºè°ƒè¯•
                candidate['rerank_score_raw'] = float(scores[i])
            
            # æŒ‰é‡æ’åºåˆ†æ•°æ’åº
            reranked_results = sorted(
                limited_candidates, 
                key=lambda x: x['rerank_score'], 
                reverse=True
            )
            
            # ä¸ºæœªé‡æ’åºçš„ç»“æœæ·»åŠ æ ‡è®°
            for candidate in candidates[max_candidates:]:
                candidate['rerank_score'] = 0.0
                candidate['rerank_note'] = "æœªé‡æ’åº"
            
            # åˆå¹¶ç»“æœ
            final_results = reranked_results + candidates[max_candidates:]
            
            return final_results[:top_k]
            
        except Exception as e:
            st.error(f"é‡æ’åºè¿‡ç¨‹å‡ºé”™: {e}")
            st.warning("å°†è¿”å›åŸå§‹æ’åºç»“æœ")
            return candidates[:top_k]
             

class HybridRetriever:
    """æ··åˆæ£€ç´¢å™¨ - BM25 + å‘é‡æ£€ç´¢"""
    
    def __init__(self, vector_collection, segments: List[AncientTextSegment]):
        self.vector_collection = vector_collection
        self.segments = segments
        self.bm25 = None
        self.segment_map = {seg.segment_id: seg for seg in segments}
        self._build_bm25_index()
        self._reranker_cache = {}  # é‡æ’åºå™¨ç¼“å­˜

    def _build_bm25_index(self):
        """æ„å»ºBM25ç´¢å¼•"""
        try:
            # åˆ†è¯
            corpus = []
            for segment in self.segments:
                tokens = list(jieba.cut(segment.content))
                corpus.append(tokens)
            
            if corpus and HAS_BM25:
                self.bm25 = BM25Okapi(corpus)
        except Exception as e:
            st.error(f"æ„å»ºBM25ç´¢å¼•å¤±è´¥: {e}")
            self.bm25 = None

    def _get_reranker(self, model_name: str = None) -> Optional[BGEReranker]:
        """è·å–é‡æ’åºå™¨å®ä¾‹ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        if not HAS_RERANKER:
            return None
        
        # ä½¿ç”¨é»˜è®¤æ¨¡å‹åç§°
        if model_name is None:
            model_name = st.session_state.get('reranker_model', 'BAAI/bge-reranker-large')
        
        # æ£€æŸ¥ç¼“å­˜
        if model_name not in self._reranker_cache:
            self._reranker_cache[model_name] = BGEReranker(model_name)
        
        return self._reranker_cache[model_name]
    
    def _should_use_reranker(self) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥ä½¿ç”¨é‡æ’åº"""
        # æ£€æŸ¥å…¨å±€å¼€å…³
        if not st.session_state.get('use_reranker', False):
            return False
        
        # æ£€æŸ¥ä¾èµ–
        if not HAS_RERANKER:
            return False
        
        return True
    
    def hybrid_search_with_filter(self, query: str, top_k: int = 10, 
                                metadata_filter: Dict[str, str] = None,
                                bm25_weight: float = None,
                                vector_weight: float = None) -> List[Dict[str, Any]]:
        """å¸¦å…ƒæ•°æ®è¿‡æ»¤çš„æ··åˆæœç´¢ - ä¿®å¤ç‰ˆ"""
        
        # æ£€æŸ¥æ˜¯å¦åº”è¯¥ä½¿ç”¨é‡æ’åº
        if self._should_use_reranker():
            return self._hybrid_search_with_rerank(
                query, top_k, 
                initial_k=min(50, max(top_k*3, 20)),  # åŠ¨æ€è°ƒæ•´åˆå§‹å€™é€‰æ•°
                metadata_filter=metadata_filter,
                bm25_weight=bm25_weight,
                vector_weight=vector_weight
            )
        
        # ä¸ä½¿ç”¨é‡æ’åºçš„å¸¸è§„æ··åˆæœç´¢
        bm25_w = bm25_weight if bm25_weight is not None else 0.3
        vector_w = vector_weight if vector_weight is not None else 0.7
        
        if not HAS_BM25 or not self.bm25:
            return self.vector_search_with_filter(query, top_k, metadata_filter)
        
        bm25_results = self.bm25_search_with_filter(query, top_k * 2, metadata_filter)
        vector_results = self.vector_search_with_filter(query, top_k * 2, metadata_filter)
        
        combined_results = self._combine_results(
            bm25_results, vector_results, bm25_w, vector_w
        )
        
        return combined_results[:top_k]

    def vector_search_with_filter(self, query: str, top_k: int, 
                             metadata_filter: Dict[str, str] = None) -> List[Dict[str, Any]]:
        """å¸¦å…ƒæ•°æ®è¿‡æ»¤çš„å‘é‡æœç´¢"""
        try:
            # æ„å»ºwhereæ¡ä»¶ - ä¿®å¤è¯­æ³•
            where_condition = None
            if metadata_filter:
                if len(metadata_filter) == 1:
                    # å•ä¸ªæ¡ä»¶
                    key, value = next(iter(metadata_filter.items()))
                    where_condition = {key: {"$eq": value}}
                else:
                    # å¤šä¸ªæ¡ä»¶ä½¿ç”¨$and
                    conditions = []
                    for key, value in metadata_filter.items():
                        conditions.append({key: {"$eq": value}})
                    where_condition = {"$and": conditions}
            
            results = self.vector_collection.query(
                query_texts=[query],
                n_results=min(top_k, self.vector_collection.count()),
                where=where_condition
            )
            
            vector_results = []
            if results['documents'] and results['documents'][0]:
                for i, doc in enumerate(results['documents'][0]):
                    segment_id = results['ids'][0][i]
                    segment = self.segment_map.get(segment_id)
                    if segment:
                        similarity = 1 - results['distances'][0][i] if results['distances'] else 1.0
                        vector_results.append({
                            'segment_id': segment_id,
                            'content': doc,
                            'metadata': asdict(segment),
                            'bm25_score': 0.0,
                            'vector_score': float(similarity)
                        })
            
            return vector_results
        except Exception as e:
            st.error(f"å‘é‡æ£€ç´¢é”™è¯¯: {e}")
            return []

    def bm25_search_with_filter(self, query: str, top_k: int, 
                            metadata_filter: Dict[str, str] = None) -> List[Dict[str, Any]]:
        """å¸¦å…ƒæ•°æ®è¿‡æ»¤çš„BM25æœç´¢"""
        if not self.bm25 or not HAS_BM25:
            return []
        
        try:
            query_tokens = list(jieba.cut(query))
            scores = self.bm25.get_scores(query_tokens)
            
            # è·å–æ’åºåçš„ç´¢å¼•
            top_indices = np.argsort(scores)[::-1]
            
            results = []
            for idx in top_indices:
                if len(results) >= top_k:
                    break
                    
                if idx < len(self.segments):
                    segment = self.segments[idx]
                    
                    # åº”ç”¨å…ƒæ•°æ®è¿‡æ»¤
                    if metadata_filter:
                        match = True
                        for key, value in metadata_filter.items():
                            segment_value = getattr(segment, key, None)
                            if segment_value != value:
                                match = False
                                break
                        if not match:
                            continue
                    
                    results.append({
                        'segment_id': segment.segment_id,
                        'content': segment.content,
                        'metadata': asdict(segment),
                        'bm25_score': float(scores[idx]),
                        'vector_score': 0.0
                    })
            
            return results
        except Exception as e:
            st.error(f"BM25æ£€ç´¢é”™è¯¯: {e}")
            return []
        
    def hybrid_search(self, query: str, top_k: int = 10,
                 bm25_weight: float = None,
                 vector_weight: float = None) -> List[Dict[str, Any]]:
        """åŸºç¡€æ··åˆæœç´¢ï¼ˆæ— è¿‡æ»¤ï¼‰"""
        return self.hybrid_search_with_filter(
            query, top_k, 
            metadata_filter=None,
            bm25_weight=bm25_weight,
            vector_weight=vector_weight
        )
    
    def _vector_search(self, query: str, top_k: int) -> List[Dict[str, Any]]:
        """åŸºç¡€å‘é‡æœç´¢ï¼ˆæ— è¿‡æ»¤ï¼‰"""
        return self.vector_search_with_filter(query, top_k, metadata_filter=None)

    def _bm25_search(self, query: str, top_k: int) -> List[Dict[str, Any]]:
        """åŸºç¡€BM25æœç´¢ï¼ˆæ— è¿‡æ»¤ï¼‰"""
        return self.bm25_search_with_filter(query, top_k, metadata_filter=None)
    
    def _hybrid_search_with_rerank(self, query: str, top_k: int = 10, 
                                 initial_k: int = 50,
                                 bm25_weight: float = None, 
                                 vector_weight: float = None,
                                 metadata_filter: Dict[str, str] = None) -> List[Dict[str, Any]]:
        """å¸¦é‡æ’åºçš„æ··åˆæ£€ç´¢ - ä¿®å¤ç‰ˆ"""
        
        # ä½¿ç”¨ä¼ å…¥çš„æƒé‡ï¼Œå¦‚æœæ²¡æœ‰ä¼ å…¥åˆ™ä½¿ç”¨é»˜è®¤å€¼
        bm25_w = bm25_weight if bm25_weight is not None else 0.3
        vector_w = vector_weight if vector_weight is not None else 0.7
        
        # è°ƒæ•´åˆå§‹æ£€ç´¢æ•°é‡ï¼Œç¡®ä¿æœ‰è¶³å¤Ÿçš„å€™é€‰
        effective_initial_k = max(initial_k, top_k * 3)
        
        # è·å–å€™é€‰ç»“æœ
        if not HAS_BM25 or not self.bm25:
            if metadata_filter:
                candidates = self.vector_search_with_filter(query, effective_initial_k, metadata_filter)
            else:
                candidates = self._vector_search(query, effective_initial_k)
        else:
            if metadata_filter:
                bm25_results = self.bm25_search_with_filter(query, effective_initial_k, metadata_filter)
                vector_results = self.vector_search_with_filter(query, effective_initial_k, metadata_filter)
            else:
                bm25_results = self._bm25_search(query, effective_initial_k)
                vector_results = self._vector_search(query, effective_initial_k)
            
            candidates = self._combine_results(
                bm25_results, vector_results, bm25_w, vector_w
            )
        
        # æ ¸å¿ƒä¿®å¤ï¼šæ£€æŸ¥å€™é€‰ç»“æœ
        if not candidates:
            st.info("æœªæ‰¾åˆ°å€™é€‰ç»“æœï¼Œè·³è¿‡é‡æ’åº")
            return []
        
        # è·å–é‡æ’åºå™¨
        reranker = self._get_reranker()
        if reranker and reranker.ensure_loaded():
            st.info(f"ğŸ”„ ä½¿ç”¨é‡æ’åºå¤„ç† {len(candidates)} ä¸ªå€™é€‰ç»“æœ")
            return reranker.rerank(query, candidates, top_k)
        else:
            st.info("é‡æ’åºä¸å¯ç”¨ï¼Œä½¿ç”¨åŸå§‹æ’åº")
            return candidates[:top_k]
    
        
    def _combine_results(self, bm25_results: List[Dict], vector_results: List[Dict],
                    bm25_weight: float, vector_weight: float) -> List[Dict[str, Any]]:
        """åˆå¹¶æ£€ç´¢ç»“æœï¼ˆä¿ç•™åŸå§‹åˆ†æ•°ï¼‰"""
        # å½’ä¸€åŒ–åˆ†æ•°
        bm25_results = self._normalize_scores(bm25_results, 'bm25_score')
        vector_results = self._normalize_scores(vector_results, 'vector_score')
        
        # åˆå¹¶ç»“æœ
        combined = {}
        
        for result in bm25_results:
            sid = result['segment_id']
            combined[sid] = result.copy()
            combined[sid]['combined_score'] = result['bm25_score'] * bm25_weight
            # ä¿ç•™åŸå§‹BM25åˆ†æ•°
            if 'bm25_score_raw' in result:
                combined[sid]['bm25_score_raw'] = result['bm25_score_raw']
        
        for result in vector_results:
            sid = result['segment_id']
            if sid in combined:
                combined[sid]['vector_score'] = result['vector_score']
                combined[sid]['combined_score'] += result['vector_score'] * vector_weight
                # ä¿ç•™åŸå§‹å‘é‡åˆ†æ•°
                if 'vector_score_raw' in result:
                    combined[sid]['vector_score_raw'] = result['vector_score_raw']
            else:
                combined[sid] = result.copy()
                combined[sid]['combined_score'] = result['vector_score'] * vector_weight
        
        # æŒ‰ç»¼åˆåˆ†æ•°æ’åº
        sorted_results = sorted(combined.values(), 
                            key=lambda x: x['combined_score'], reverse=True)
        
        return sorted_results
    
    def _normalize_scores(self, results: List[Dict], score_key: str) -> List[Dict]:
        """å½’ä¸€åŒ–åˆ†æ•°ï¼ˆä¿ç•™åŸå§‹åˆ†æ•°ï¼‰"""
        if not results:
            return results
        
        scores = [r[score_key] for r in results]
        max_score = max(scores) if scores else 1.0
        min_score = min(scores) if scores else 0.0
        
        if max_score == min_score:
            return results
        
        for result in results:
            # ä¿å­˜åŸå§‹åˆ†æ•°
            result[f'{score_key}_raw'] = result[score_key]
            # è®¡ç®—å½’ä¸€åŒ–åˆ†æ•°
            result[score_key] = (result[score_key] - min_score) / (max_score - min_score)
        
        return results
